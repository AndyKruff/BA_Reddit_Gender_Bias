{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andreas\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\Andreas\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "C:\\Users\\Andreas\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.noijjg62emaszi6nyurl6jbkm4evbgm7.gfortran-win_amd64.dll\n",
      "C:\\Users\\Andreas\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define research object names for data import\n",
    "\n",
    "user_roles = [\"Ignored\", \"Lurker\",\"Contributor\",\"casual_commentator\"]\n",
    "\n",
    "subreddits = [\"TwoXChromosomes\",\"gardening\",\"Parenting\",\n",
    "\"AskMen\",\"AskWomen\",\"unpopularopinion\",\"teenagers\",\n",
    "              \"funny\",\"technology\",\"science\",\"Conservative\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(df_,experiment,research_object):\n",
    "    \n",
    "    # Generate nested list with all tokenized sentences \n",
    "    token_list = df_[\"token_list\"].tolist()\n",
    "    flat_token_list = [item for sublist in token_list for item in sublist]\n",
    "    from gensim.models import FastText\n",
    "    \n",
    "    # Train model for Sentiment Analysis with min_count = 15\n",
    "    model_sent = FastText(flat_token_list,min_count=15, window=10,workers=6,sg=1, vector_size=50, epochs=10, min_n = 3, max_n=6,shrink_windows=False,ns_exponent=0.75, negative=20,sample=0,alpha=0.025)#\n",
    "    model_sent.save(f'../models/{experiment}/fasttext_{research_object}_senti.bin')\n",
    "\n",
    "    # Train model for WEAT Analysis with min_count = 0\n",
    "    model_weat = FastText(flat_token_list,min_count=0, window=10,workers=6,sg=1, vector_size=50, epochs=10, min_n = 3, max_n=6,shrink_windows=False,ns_exponent=0.75, negative=20,sample=0,alpha=0.025)#\n",
    "    model_weat.save(f'../models/{experiment}/fasttext_{research_object}_weat.bin')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignored\n",
      "1224.3098423480988\n",
      "Lurker\n",
      "6467.375055074692\n",
      "Contributor\n",
      "1558.0007810592651\n",
      "casual_commentator\n",
      "11721.998423814774\n"
     ]
    }
   ],
   "source": [
    "for i in user_roles:\n",
    "    print(i)\n",
    "    # Read in preprocessed dataframe for user group\n",
    "    df = pd.read_hdf(f'../datasets/{i}.h5', i) \n",
    "    start = time.time()\n",
    "    train_models(df, \"user_level\", i)\n",
    "    end = time.time()\n",
    "    print(end - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in subreddits:\n",
    "    print(i)\n",
    "    # Read in preprocessed dataframe for subreddit\n",
    "\n",
    "    df = pd.read_hdf(f'../datasets/{i}.h5', i) \n",
    "    start = time.time()\n",
    "    train_models(df, \"subreddit_level\", i)\n",
    "    end = time.time()\n",
    "    print(end - start)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
